{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Name: Artificial Art Detection\n",
        "\n",
        "# Members:\n",
        "1. Bryan Nguyen\n",
        "2. Jesus Perez Arias\n",
        "3. Brian Pham\n",
        "4. Runyi Yang\n",
        "5. Mohamad Saleh\n",
        "6. Kevin Trochez\n",
        "7. Joseph Comeaux\n",
        "8. Vidal Zazueta\n",
        "9. Jesse Gonzalez\n",
        "10. Alan Espinosa\n"
      ],
      "metadata": {
        "id": "6LuHDaO7JdUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ],
      "metadata": {
        "id": "WakRTsCRHBCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Overview of the dataset\n",
        "\n",
        "The dataset contains royalty-free images. One-third of this dataset contains images that feature humans which are then compared with similar AI-generated images of such humans."
      ],
      "metadata": {
        "id": "33q3qVA5HI9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Brief description of the problem statement\n",
        "\n",
        "\n",
        "The royalty-free human images within the dataset that contains are to be paired with equivalent images that have been generated by generative models (AI-generated images). By pairing such images together, a direct comparison can be made between real and AI-generated content. This in turn will make it easier to develop and evaluate image authenticity detection systems."
      ],
      "metadata": {
        "id": "cwRcFmsNJCn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Data source and collection process\n",
        "\n"
      ],
      "metadata": {
        "id": "tzRt7W1xJD8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authentic image data is sourced from Shutterstock, which is a provider of royalty-free photography, while AI-generated image data is sourced from DeepMedia, which is a company that specialzes in deepfake detection and AI security.\n",
        "\n",
        "The data collection process..."
      ],
      "metadata": {
        "id": "VN_UUX8lRKJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Review of PreML Checklist**"
      ],
      "metadata": {
        "id": "r1ggDb0QHOgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Data Completeness**: Check for missing values, duplicates, and incorrect entries.\n",
        "\n",
        "Of the given 5,540 provided entries, there are no mismatched or missing entries. Entries appear to be correct, and there are no duplicated or incorrect entries, either."
      ],
      "metadata": {
        "id": "jRuyBrpLHTCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Representativeness**: Evaluate if the dataset represents different subgroups.\n"
      ],
      "metadata": {
        "id": "35DkFSlGJGgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Bias & Fairness**: Check for potential biases in data labeling and distribution.\n",
        "\n",
        "Although there is no potential bias in data labeling, there is a potential bias within data distribution, where there could be a distribution imbalance between authentic and AI-generated images."
      ],
      "metadata": {
        "id": "MFJbYlB5JHo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Privacy Considerations**: Discuss any privacy concerns in the dataset.\n",
        "\n",
        "Some of the collected images of humans might superficially resemble a real-life person, but it can be safely assumed for the purposes of the dataset that any resemblance to a person, both living and dead, is entirely coincidental unless directly stated otherwise."
      ],
      "metadata": {
        "id": "fKuC4dkbJI3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Labeling Consistency**: Ensure labels are accurate and consistent.\n",
        "\n",
        "The labeling of data is very consistent. No data value is missing a label, and the data is categorized between \"Class 0\" and \"Class 1\" to distinguish between authentic and AI-generated images."
      ],
      "metadata": {
        "id": "77eC4oDXJJ82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Assessment & Preprocessing**"
      ],
      "metadata": {
        "id": "7qUdgBEVHbqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Data Overview** (Pandas data info, describe)\n"
      ],
      "metadata": {
        "id": "vFuXG5K_ITQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh13bpMbnK4t",
        "outputId": "3f52c76f-f38d-4f5d-e10b-9e74bff3b3e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.1.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOzPXDU3Pagu",
        "outputId": "512bd41d-76fd-4cbc-90b3-8744e13bcfd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle_api/kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUyKXcZ7oE0Q",
        "outputId": "bb1ba40b-90b5-429b-82d2-580500adbc77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data from google drive."
      ],
      "metadata": {
        "id": "lC2mxmD3RErK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-jJY915rEBi",
        "outputId": "2c88dd3d-30e5-45bf-a420-18cbc3fe1af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4.0K\n",
            "-rw------- 1 root root 67 Mar 22 02:24 kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Ugnq-4jUolsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"alessandrasala79/ai-vs-human-generated-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrQop3Xgo0no",
        "outputId": "d51aaf55-17fc-456e-fc86-9ff2112a4638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/alessandrasala79/ai-vs-human-generated-dataset?dataset_version_number=4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.76G/9.76G [01:41<00:00, 103MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/alessandrasala79/ai-vs-human-generated-dataset/versions/4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset path\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/alessandrasala79/ai-vs-human-generated-dataset/versions/4\""
      ],
      "metadata": {
        "id": "CwY2Jbf-sye0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the dataset\n",
        "train_df = pd.read_csv(f\"{dataset_path}/train.csv\")\n",
        "test_df = pd.read_csv(f\"{dataset_path}/test.csv\")"
      ],
      "metadata": {
        "id": "L2uWF2TXs2GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qXaN7F0PqkNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Checking if data includes information that can predict the target"
      ],
      "metadata": {
        "id": "_1wKVPz5RO8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns in training dataset: \", train_df.columns)\n",
        "print(\"Columns in test dataset: \", test_df.columns)"
      ],
      "metadata": {
        "id": "H_0YkVNyRVR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b1d877-f9a6-452d-dbb1-6b39bb420215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in training dataset:  Index(['Unnamed: 0', 'file_name', 'label'], dtype='object')\n",
            "Columns in test dataset:  Index(['id'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Target column in training set: \", \"label\" in train_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_WKFlU5tlm9",
        "outputId": "8c05a147-ab53-4eae-d6ca-8a623dd19842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target column in training set:  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Granularity of training and prediction matching"
      ],
      "metadata": {
        "id": "VkYh-J9gRvSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training data shape: \", train_df.shape)\n",
        "print(\"Test data shape: \", test_df.shape)"
      ],
      "metadata": {
        "id": "sLoKQXmLR1bM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb233dc-2c3c-4edf-87c6-b949ce63b662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape:  (79950, 3)\n",
            "Test data shape:  (5540, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3 Labeled Data"
      ],
      "metadata": {
        "id": "U-9TDYjESJ-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Label distribution in training data: \")\n",
        "print(train_df['label'].value_counts())"
      ],
      "metadata": {
        "id": "_nefzzGpSOFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db56c6cd-b594-4aa0-c4a4-49a32a8a7b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution in training data: \n",
            "label\n",
            "1    39975\n",
            "0    39975\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4 Data Accuracy"
      ],
      "metadata": {
        "id": "OgCgrflnSBS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data accuracy: \")\n",
        "print(train_df.describe())"
      ],
      "metadata": {
        "id": "Nt_1sElNSAnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e2aa312-9138-4dc8-9b96-6abd87994bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data accuracy: \n",
            "         Unnamed: 0         label\n",
            "count  79950.000000  79950.000000\n",
            "mean   39974.500000      0.500000\n",
            "std    23079.721348      0.500003\n",
            "min        0.000000      0.000000\n",
            "25%    19987.250000      0.000000\n",
            "50%    39974.500000      0.500000\n",
            "75%    59961.750000      1.000000\n",
            "max    79949.000000      1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Check for duplicated rows in training data: \")\n",
        "print(train_df.duplicated().sum())"
      ],
      "metadata": {
        "id": "j_nTgAoLSaAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea3609f-5815-4222-b7d7-6082a05a5014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check for duplicated rows in training data: \n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Check for duplicated rows in test data: \")\n",
        "print(test_df.duplicated().sum())"
      ],
      "metadata": {
        "id": "3yOvo9tYSpQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9888b0f8-63bb-4f12-ee97-86f52a3b90ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check for duplicated rows in test data: \n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Check for missing values: \")\n",
        "print(train_df.isnull().sum())"
      ],
      "metadata": {
        "id": "e0zFE-yfShI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d9b9fb-a293-4d7c-9a6f-5584b502eed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check for missing values: \n",
            "Unnamed: 0    0\n",
            "file_name     0\n",
            "label         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.5 Enough Data Check"
      ],
      "metadata": {
        "id": "s66tWQwGStpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of samples in training data set: \", len(train_df))\n",
        "print(\"Number of samples in test data set: \", len(test_df))\n",
        "print(\"Number of features per sample: \", train_df.shape[1] - 1)\n",
        "print(\"Enough samples for training model\", len(train_df) > 10_000)"
      ],
      "metadata": {
        "id": "wMZ1CwnZSj2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1a3bd3-d0d0-4fc9-829e-ae49fe4daabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in training data set:  79950\n",
            "Number of samples in test data set:  5540\n",
            "Number of features per sample:  2\n",
            "Enough samples for training model True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.6 Data Accessilble to team\n",
        "Yes data can be loaded with pandas and is in CSV format."
      ],
      "metadata": {
        "id": "9E0yrFQzTNEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.7 Reading data in time"
      ],
      "metadata": {
        "id": "pXxeE05sTfax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = f\"{dataset_path}/train.csv\"\n",
        "test_path = f\"{dataset_path}/test.csv\"\n",
        "\n",
        "%timeit pd.read_csv(train_path)\n",
        "%timeit pd.read_csv(test_path)"
      ],
      "metadata": {
        "id": "E8zZ82IrTjT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e4ee0e-ee2c-48fe-cab9-ae2bb9406890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105 ms ± 16.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "7.16 ms ± 872 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.8 Documentation for each field of data"
      ],
      "metadata": {
        "id": "KzIYRCaxKSrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Handling Missing Data** (Count missing values per column)\n"
      ],
      "metadata": {
        "id": "WzNZAemXJMg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.9 Missing value in the dataset"
      ],
      "metadata": {
        "id": "RlLK8k_wKulZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in train dataset\n",
        "missing_values = train_df.isnull().sum()\n",
        "print(\"Missing values per column:\\n\", missing_values)\n",
        "\n",
        "# Check for duplicate rows in train dataset\n",
        "duplicate_rows = train_df.duplicated().sum()\n",
        "print(\"Number of duplicate rows:\", duplicate_rows)\n"
      ],
      "metadata": {
        "id": "tVCOo3N3JOMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in test dataset\n",
        "missing_values = test_df.isnull().sum()\n",
        "print(\"Missing values per column:\\n\", missing_values)\n",
        "\n",
        "# Check for duplicate rows in test dataset\n",
        "duplicate_rows = test_df.duplicated().sum()\n",
        "print(\"Number of duplicate rows:\", duplicate_rows)\n"
      ],
      "metadata": {
        "id": "i80YP62_JPvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bHEqDJZlfEID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Class Balance Check** (Just for the classification problems)\n"
      ],
      "metadata": {
        "id": "vnBXml69JNhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Feature Distributions**"
      ],
      "metadata": {
        "id": "myC4Xnn7JVMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Compute average pixel intensity for each digit class\n",
        "avg_intensity = [x_train[y_train == i].mean() for i in range(10)]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=list(range(10)), y=avg_intensity)\n",
        "plt.xlabel(\"Digit Class\")\n",
        "plt.ylabel(\"Average Pixel Intensity\")\n",
        "plt.title(\"Average Pixel Intensity Per Digit Class in MNIST\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FQzzLcWcMt0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_quadrant_density(images):\n",
        "    h, w = images.shape[1], images.shape[2]\n",
        "    top_half = images[:, :h//2, :].sum(axis=(1,2))\n",
        "    bottom_half = images[:, h//2:, :].sum(axis=(1,2))\n",
        "    left_half = images[:, :, :w//2].sum(axis=(1,2))\n",
        "    right_half = images[:, :, w//2:].sum(axis=(1,2))\n",
        "\n",
        "    return top_half, bottom_half, left_half, right_half\n",
        "\n",
        "top, bottom, left, right = compute_quadrant_density(x_train)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.kdeplot(top, label=\"Top Half\", shade=True)\n",
        "sns.kdeplot(bottom, label=\"Bottom Half\", shade=True)\n",
        "sns.kdeplot(left, label=\"Left Half\", shade=True)\n",
        "sns.kdeplot(right, label=\"Right Half\", shade=True)\n",
        "plt.xlabel(\"Total Pixel Intensity\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.title(\"Pixel Density Distribution Across Image Quadrants\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wco0Dz3kMuLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Handling Missing Values**\n"
      ],
      "metadata": {
        "id": "wCC0fUDgJPQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XUoP_ShRMrgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Outlier Removal (if applicable)**\n"
      ],
      "metadata": {
        "id": "rh3xh9tsJQaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2eHVxUWJeTE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Normalization**"
      ],
      "metadata": {
        "id": "PFKHYAutJRdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to range [0,1]\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "8b2GjgXNdrwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary & Findings**"
      ],
      "metadata": {
        "id": "58E75Oi6IZzz"
      }
    }
  ]
}